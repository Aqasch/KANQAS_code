[general]
episodes = 10000

[env]
type = classic
num_qubits = 3
num_layers = 12
fn_type = fidelty_reward
accept_err = 0.98
thresholds = [0.98]
switch_episodes = [100000]
curriculum_type = VanillaCurriculum

[problem]
type = Bell
noise = 0
noise_prob_1q = 0
noise_prob_2q = 0

[agent]
batch_size = 1000
memory_size = 15000
neurons = [30,30,30]
dropout = 0.
learning_rate = 0.0005
angles = 0
en_state = 0
agent_type = DDQN
agent_class = DDQN
init_net = 0

update_target_net = 50
final_gamma = 0.005
epsilon_decay = 0.99995
epsilon_min = 0.05
epsilon_restart = 1.0